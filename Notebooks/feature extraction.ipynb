{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "DATASET_PATH = \"E:/Coding/Advanced ML/sample_train_data\"\n",
    "IMG_SIZE = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(extract_func, desc=\"Processing\"):\n",
    "    images = []\n",
    "    filenames = os.listdir(DATASET_PATH)\n",
    "    \n",
    "    for file in tqdm(filenames, desc=desc):  \n",
    "        img_path = os.path.join(DATASET_PATH, file)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            continue  # Skip unreadable images\n",
    "        \n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        \n",
    "        features = extract_func(img, gray)  # Extract features\n",
    "        images.append(features)\n",
    "    \n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RGBW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rgbw_features(img):\n",
    "    r, g, b = cv2.split(img)\n",
    "    w = (r + g + b) // 3  \n",
    "    return np.array([r.mean(), g.mean(), b.mean(), w.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting RGBW: 100%|██████████| 20000/20000 [03:11<00:00, 104.55it/s]\n"
     ]
    }
   ],
   "source": [
    "CACHE_FILE = \"features_rgbw.npy\"\n",
    "rgbw_features = process_images(lambda img, gray: extract_rgbw_features(img), \"Extracting RGBW\")\n",
    "np.save(CACHE_FILE, rgbw_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(gray):\n",
    "    features, _ = hog(gray, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True)\n",
    "    hist, _ = np.histogram(features, bins=32, range=(0, np.max(features)), density=True)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting HOG: 100%|██████████| 20000/20000 [08:09<00:00, 40.85it/s]\n"
     ]
    }
   ],
   "source": [
    "CACHE_FILE = \"features_hog.npy\"\n",
    "hog_features = process_images(lambda img, gray: extract_hog_features(gray), \"Extracting HOG\")\n",
    "np.save(CACHE_FILE, hog_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LBP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp_features(gray):\n",
    "    lbp = local_binary_pattern(gray, P=8, R=1, method=\"uniform\")\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=59, range=(0, 59), density=True)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting LBP: 100%|██████████| 20000/20000 [01:03<00:00, 317.23it/s]\n"
     ]
    }
   ],
   "source": [
    "CACHE_FILE = \"features_lbp.npy\"\n",
    "lbp_features = process_images(lambda img, gray: extract_lbp_features(gray), \"Extracting LBP\")\n",
    "np.save(CACHE_FILE, lbp_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fourier_features(gray):\n",
    "    H, W = gray.shape\n",
    "    fft_img = np.fft.fft2(gray)\n",
    "    fft_shift = np.fft.fftshift(fft_img)\n",
    "    magnitude_spectrum = np.abs(fft_shift)\n",
    "    low_freq = magnitude_spectrum[:H//4, :W//4].mean()\n",
    "    mid_freq = magnitude_spectrum[H//4:H//2, W//4:W//2].mean()\n",
    "    high_freq = magnitude_spectrum[H//2:, W//2:].mean()\n",
    "    return np.array([low_freq, mid_freq, high_freq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Fourier: 100%|██████████| 20000/20000 [00:51<00:00, 387.33it/s]\n"
     ]
    }
   ],
   "source": [
    "CACHE_FILE = \"features_fda.npy\"\n",
    "fourier_features = process_images(lambda img, gray: extract_fourier_features(gray), \"Extracting Fourier\")\n",
    "np.save(CACHE_FILE, fourier_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Level Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ela_features(img):\n",
    "    cv2.imwrite(\"temp.jpg\", img, [cv2.IMWRITE_JPEG_QUALITY, 90])\n",
    "    compressed = cv2.imread(\"temp.jpg\")\n",
    "    ela = cv2.absdiff(img, compressed)\n",
    "    return np.array([ela.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting ELA: 100%|██████████| 20000/20000 [02:53<00:00, 115.13it/s]\n"
     ]
    }
   ],
   "source": [
    "CACHE_FILE = \"features_ela.npy\"\n",
    "ela_features = process_images(lambda img, gray: extract_ela_features(img), \"Extracting ELA\")\n",
    "np.save(CACHE_FILE, ela_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Binary Pattern Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbpv_features(gray):\n",
    "    if gray is None or gray.size == 0:\n",
    "        raise ValueError(\"Invalid image: empty or not loaded correctly\")\n",
    "\n",
    "    lbpv = local_binary_pattern(gray, P=8, R=1, method=\"var\")\n",
    "\n",
    "    # Replace NaN and Inf values\n",
    "    lbpv = np.nan_to_num(lbpv, nan=0)\n",
    "\n",
    "    # Ensure max is finite\n",
    "    max_val = np.max(lbpv)\n",
    "    if not np.isfinite(max_val) or max_val == 0:\n",
    "        max_val = 1  # Avoid division issues\n",
    "\n",
    "    hist, _ = np.histogram(lbpv.ravel(), bins=59, range=(0, max_val), density=True)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting LBPV: 100%|██████████| 20000/20000 [01:05<00:00, 304.18it/s]\n"
     ]
    }
   ],
   "source": [
    "CACHE_FILE = \"features_lbpv.npy\"\n",
    "lbpv_features = process_images(lambda img, gray: extract_lbpv_features(gray), \"Extracting LBPV\")\n",
    "np.save(CACHE_FILE, lbpv_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Gamut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_gamut(img):\n",
    "    hist = cv2.calcHist([img], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Color Gamut: 100%|██████████| 20000/20000 [00:46<00:00, 425.80it/s]\n"
     ]
    }
   ],
   "source": [
    "CACHE_FILE = \"features_colorgamut.npy\"\n",
    "color_gamut_features = process_images(lambda img, gray: extract_color_gamut(img), \"Extracting Color Gamut\")\n",
    "np.save(CACHE_FILE, color_gamut_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fractal Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fractal_dimension(gray, threshold=128):  \n",
    "    # Ensure the image is binary by thresholding\n",
    "    img = gray < threshold  \n",
    "    sizes = 2 ** np.arange(1, 6)\n",
    "\n",
    "    counts = []\n",
    "    for size in sizes:\n",
    "        S = np.floor(gray.shape[0] / size) * size  # Ensure divisibility\n",
    "        box_count = np.sum(img[:int(S), :int(S)].reshape(-1, size, size), axis=(1, 2))\n",
    "        counts.append(np.sum(box_count > 0))\n",
    "\n",
    "    coeffs = np.polyfit(np.log(sizes), np.log(counts), 1)  \n",
    "    return np.array([coeffs[0]])  # Return as a feature array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Fractal Dimension:  20%|█▉        | 3973/20000 [00:10<00:41, 390.44it/s]C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_16936\\2295806612.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  coeffs = np.polyfit(np.log(sizes), np.log(counts), 1)\n",
      "Extracting Fractal Dimension: 100%|██████████| 20000/20000 [00:50<00:00, 394.24it/s]\n"
     ]
    }
   ],
   "source": [
    "CACHE_FILE = \"features_fractal.npy\"\n",
    "fractal_features = process_images(lambda img, gray: fractal_dimension(gray), \"Extracting Fractal Dimension\")\n",
    "np.save(CACHE_FILE, fractal_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
